{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0307edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the openai module using pip\n",
    "# pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31282bd",
   "metadata": {},
   "source": [
    "##### Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fc94e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import openai\n",
    "import random\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e829c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca6773",
   "metadata": {},
   "source": [
    "##### Importing Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65dc2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f85fd",
   "metadata": {},
   "source": [
    "##### Setting OpenAI API Key to Access GPT-3 Model Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebf74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311168d",
   "metadata": {},
   "source": [
    "### Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85018648",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2a0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative paths to create variables that point to the CSV files\n",
    "covid_lies_original = os.path.join(base_path, 'Original_dataset', 'covid-19.csv')\n",
    "fake_news_original = os.path.join(base_path, 'Original_dataset', 'fake_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddd9c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the CSV files into pandas dataframes\n",
    "df_covid_original = pd.read_csv(covid_lies_original)\n",
    "df_news_original = pd.read_csv(fake_news_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f80deab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Our daily update is published. States reported...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>President Trump Asked What He Would Do If He W...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              tweet label\n",
       "0   1  Our daily update is published. States reported...  real\n",
       "1   2             Alfalfa is the only cure for COVID-19.  fake\n",
       "2   3  President Trump Asked What He Would Do If He W...  fake"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_covid_original.head(3) #return the first 3 rows of the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65269f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>FALSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  label\n",
       "0  We have less Americans working now than in the...  FALSE\n",
       "1  When Obama was sworn into office, he DID NOT u...  FALSE\n",
       "2  Says Having organizations parading as being so...  FALSE"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_original.head(3) #return the first 3 rows of the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c300526",
   "metadata": {},
   "source": [
    "##### Modifying the structure of the dataframes for our needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eda8118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our daily update is published. States reported...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alfalfa is the only cure for COVID-19.</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Trump Asked What He Would Do If He W...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>States reported 630 deaths. We are still seein...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the sixth time a global health emergen...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post      label\n",
       "0  Our daily update is published. States reported...      Truth\n",
       "1             Alfalfa is the only cure for COVID-19.  Deception\n",
       "2  President Trump Asked What He Would Do If He W...  Deception\n",
       "3  States reported 630 deaths. We are still seein...      Truth\n",
       "4  This is the sixth time a global health emergen...      Truth"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covid Dataset\n",
    "\n",
    "columns_to_remove = ['id']\n",
    "\n",
    "#remove columns and create new DataFrame\n",
    "new_df_covid_original = df_covid_original.drop(columns_to_remove, axis=1) \n",
    "\n",
    "# Define the old column name and the new column name\n",
    "old_column_name = \"tweet\"\n",
    "new_column_name = \"post\"\n",
    "\n",
    "# Change the column name\n",
    "new_df_covid_original.rename(columns={old_column_name: new_column_name}, inplace=True)\n",
    "\n",
    "# replace the values in the 'label' column of dataframe with new values\n",
    "new_df_covid_original['label'] = new_df_covid_original['label'].replace('real', 'Truth')\n",
    "new_df_covid_original['label'] = new_df_covid_original['label'].replace('fake', 'Deception')\n",
    "new_df_covid_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d2ec49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post      label\n",
       "0  We have less Americans working now than in the...  Deception\n",
       "1  When Obama was sworn into office, he DID NOT u...  Deception\n",
       "2  Says Having organizations parading as being so...  Deception\n",
       "3     Says nearly half of Oregons children are poor.      Truth\n",
       "4  On attacks by Republicans that various program...      Truth"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fake news Dataset\n",
    "\n",
    "old_column_name = \"Statement\"\n",
    "new_column_name = \"post\"\n",
    "\n",
    "# Change the columns name\n",
    "df_news_original.rename(columns={old_column_name: new_column_name}, inplace=True)\n",
    "\n",
    "# replace the values in the 'label' column of dataframe with new values\n",
    "df_news_original['label'] = df_news_original['label'].replace('TRUE', 'Truth')\n",
    "df_news_original['label'] = df_news_original['label'].replace('FALSE', 'Deception')\n",
    "df_news_original.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa066507",
   "metadata": {},
   "source": [
    "##### Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f44812ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth        1120\n",
       "Deception    1020\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_covid_original['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db11a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth        1336\n",
       "Deception    1232\n",
       "Label           1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_original['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564cdfe",
   "metadata": {},
   "source": [
    "#### text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8714b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove URLs\n",
    "# new_df_covid_original['post'] = new_df_covid_original['post'].apply(lambda x: re.sub(r'http\\S+|www.\\S+', '', x))\n",
    "\n",
    "# # Remove words starting with '@'\n",
    "# new_df_covid_original['post'] = new_df_covid_original['post'].apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "\n",
    "# # Remove hashtags\n",
    "# new_df_covid_original['post'] = new_df_covid_original['post'].apply(lambda x: re.sub(r'#\\w+', '', x))\n",
    "\n",
    "# # Remove tick and cross signs\n",
    "# new_df_covid_original['post'] = new_df_covid_original['post'].apply(lambda x: re.sub(r'✔️|✖️', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e24abe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)  # Remove URLs\n",
    "    text = re.sub('[@&]\\w+', '', text)  # Remove words starting with @ and &\n",
    "    text = re.sub('#\\w+', '', text)  # Remove hashtags\n",
    "    text = re.sub('\\?+', '', text)  # Remove question marks\n",
    "    text = re.sub('[\\u2713\\u2717]', '', text)  # Remove tick and cross signs\n",
    "    text = re.sub('[\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U0001F926-\\U0001F937\\U0001F1E6-\\U0001F1FF\\U0001F191-\\U0001F19A\\U0000231A-\\U0000231B\\U00002328-\\U000023FA\\U0001F30D-\\U0001F30F\\U0001F315-\\U0001F315\\U0001F31C-\\U0001F31C\\U0001F321-\\U0001F321]', '', text)  # Remove emojis\n",
    "    return text\n",
    "\n",
    "new_df_covid_original['post'] = new_df_covid_original['post'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3294bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_covid_original = new_df_covid_original.drop_duplicates(subset='post')\n",
    "df_news_original = df_news_original.drop_duplicates(subset='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94cdb1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth        1118\n",
       "Deception    1017\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_covid_original['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5ea2979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth        668\n",
       "Deception    616\n",
       "Label          1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_original['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10470a23",
   "metadata": {},
   "source": [
    "#### Remove web link from the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4cb6323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_66641/1130230404.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  new_df_covid_original['post'] = new_df_covid_original['post'].str.replace(r'http\\S+|www.\\S+', '', case=False)\n"
     ]
    }
   ],
   "source": [
    "new_df_covid_original['post'] = new_df_covid_original['post'].str.replace(r'http\\S+|www.\\S+', '', case=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06bbcb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth        1118\n",
       "Deception    1017\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_covid_original['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0349dffb",
   "metadata": {},
   "source": [
    "#### Creating Truth and Deception Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f41f07",
   "metadata": {},
   "source": [
    "##### Truth Covid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c94fe24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a random sample of 250 rows from corona dataset where the value in the 'label' column is 'Truth'\n",
    "covid_truth = new_df_covid_original.loc[new_df_covid_original['label']=='Truth'].sample(n=250)\n",
    "covid_truth['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20b994dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the truth covid dataset in a csv file\n",
    "covid_truth.to_csv(os.path.join(base_path,'selected_dataset','covid_truth.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79d78af",
   "metadata": {},
   "source": [
    "##### Deception Covid Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60fc128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deception    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a random sample of 250 rows from corona dataset where the value in the 'label' column is 'Deception'\n",
    "covid_deception = new_df_covid_original.loc[new_df_covid_original['label']=='Deception'].sample(n=250)\n",
    "covid_deception['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c2a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the deceptive covid dataset in a csv file\n",
    "covid_deception.to_csv(os.path.join(base_path,'selected_dataset','covid_deception.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6a768",
   "metadata": {},
   "source": [
    "##### Truth News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a793385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a random sample of 250 rows from news dataset where the value in the 'label' column is 'Truth'\n",
    "news_truth = df_news_original.loc[df_news_original['label']=='Truth'].sample(n=250)\n",
    "news_truth['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0940e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the truth news dataset in a csv file\n",
    "news_truth.to_csv(os.path.join(base_path,'selected_dataset','news_truth.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d3b21",
   "metadata": {},
   "source": [
    "##### Deception News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "912fe5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deception    250\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a random sample of 250 rows from news dataset where the value in the 'label' column is 'Deception'\n",
    "news_deception = df_news_original.loc[df_news_original['label']=='Deception'].sample(n=250)\n",
    "news_deception['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7e4bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the deceptive news dataset in a csv file\n",
    "news_deception.to_csv(os.path.join(base_path,'selected_dataset','news_deception.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb39d9f2",
   "metadata": {},
   "source": [
    "##### Merging Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3cfeb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultant CSV after joining all CSV files at a particular location...\n"
     ]
    }
   ],
   "source": [
    "# the path for joining multiple files\n",
    "files = os.path.join(base_path,'selected_dataset', \"*.csv\")\n",
    "\n",
    "# list of merged files returned\n",
    "files = glob.glob(files)\n",
    "\n",
    "print(\"Resultant CSV after joining all CSV files at a particular location...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27e2b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining files with concat and read_csv\n",
    "df = pd.concat(map(pd.read_csv, files), ignore_index=True)\n",
    "df.to_csv(os.path.join(base_path,'selected_dataset','merged_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76a8b240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Truth        3025\n",
       "Deception    3025\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "537f800b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6050"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3372a",
   "metadata": {},
   "source": [
    "### Mini Datset Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c03ebb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:  India Tracker (As on 06 September 2020 08:0...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: India registers Recoveries of 65081 in the l...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small fraction of deaths in long-term care f...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Following the national trend 17 States/UTs ha...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update from the  There are three new cases of ...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  label\n",
       "0  :  India Tracker (As on 06 September 2020 08:0...  Truth\n",
       "1  : India registers Recoveries of 65081 in the l...  Truth\n",
       "2  A small fraction of deaths in long-term care f...  Truth\n",
       "3   Following the national trend 17 States/UTs ha...  Truth\n",
       "4  Update from the  There are three new cases of ...  Truth"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "dataset_selected = pd.read_csv(os.path.join(base_path,'selected_dataset','merged_dataset.csv'))\n",
    "dataset_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c20248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the two classes\n",
    "class_1 = dataset_selected[dataset_selected['label'] == 'Deception']\n",
    "class_2 = dataset_selected[dataset_selected['label'] == 'Truth']\n",
    "\n",
    "# Randomly select 5 samples from each class\n",
    "class_1_samples = class_1.sample(n=5, random_state=42)\n",
    "class_2_samples = class_2.sample(n=5, random_state=42)\n",
    "\n",
    "# Combine the selected samples\n",
    "selected_samples = pd.concat([class_1_samples, class_2_samples])\n",
    "\n",
    "# Save the selected samples to a new CSV file\n",
    "selected_samples.to_csv(os.path.join(base_path,'selected_dataset','mini_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80b37bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is a Nipah Virus outbreak in India amids...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Poll Finds 38% of Americans Say They Will Not...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Gates Foundation \"has the patent for this ...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tell me what Madeleine Albrights position was ...</td>\n",
       "      <td>Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(John) Kasich was the architect who balanced t...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>As a result of Roe vs. Wade, Americas maternal...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is when everyone has the opportunity to be as...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Energy nominee Steven Chu has called coal \"his...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>: India's  Cases per Million population is amo...</td>\n",
       "      <td>Truth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post      label\n",
       "0  There is a Nipah Virus outbreak in India amids...  Deception\n",
       "1  \"Poll Finds 38% of Americans Say They Will Not...  Deception\n",
       "2  When Obama was sworn into office, he DID NOT u...  Deception\n",
       "3  The Gates Foundation \"has the patent for this ...  Deception\n",
       "4  Tell me what Madeleine Albrights position was ...  Deception\n",
       "5  (John) Kasich was the architect who balanced t...      Truth\n",
       "6  As a result of Roe vs. Wade, Americas maternal...      Truth\n",
       "7   is when everyone has the opportunity to be as...      Truth\n",
       "8  Energy nominee Steven Chu has called coal \"his...      Truth\n",
       "9  : India's  Cases per Million population is amo...      Truth"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "mini_dataset = pd.read_csv(os.path.join(base_path,'selected_dataset','mini_dataset.csv'), index_col=None)\n",
    "mini_dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac170d",
   "metadata": {},
   "source": [
    "## GPT-3 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed36efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#arguments:\n",
    "\n",
    "    #1. prompt - string represting the text prompt for the language model to complete\n",
    "    #2. model - name of the OpenAI GPT-3 langauge model to use for text classification\n",
    "    #3. n - integer that specifies the number of responses to return from the OpenAI API\n",
    "    \n",
    "def classify_text(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Label the text as 'Deception' or 'Truth'\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=10,\n",
    "        temperature=0.5,\n",
    "        stop=[\".\"]\n",
    "    )\n",
    "    prediction = completion.choices[0].message['content'].strip()\n",
    "    label = prediction.split()[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa17e3",
   "metadata": {},
   "source": [
    "## Zero-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82e399e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number : 0\n",
      "Sample Post:  There is a Nipah Virus outbreak in India amidst coronavirus pandemic, according to a warning form the WHO.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Truth\n",
      "sample number : 1\n",
      "Sample Post:  \"Poll Finds 38% of Americans Say They Will Not Drink Corona Beer Because of Virus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Truth\n",
      "sample number : 2\n",
      "Sample Post:  When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 3\n",
      "Sample Post:  The Gates Foundation \"has the patent for this coronavirus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 4\n",
      "Sample Post:  Tell me what Madeleine Albrights position was on the War on Iraq. I wouldnt be surprised if she supported it.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 5\n",
      "Sample Post:  (John) Kasich was the architect who balanced the budget, cut spending, created a surplus, igniting record job creation.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n",
      "sample number : 6\n",
      "Sample Post:  As a result of Roe vs. Wade, Americas maternal mortality rate dropped dramatically.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n",
      "sample number : 7\n",
      "Sample Post:   is when everyone has the opportunity to be as healthy as possible. Learn about the role of culture in your efforts to stop :  \n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n",
      "sample number : 8\n",
      "Sample Post:  Energy nominee Steven Chu has called coal \"his worst nightmare.\"\n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n",
      "sample number : 9\n",
      "Sample Post:  : India's  Cases per Million population is amongst the lowest in the world; which stands at 3102 for India and 3527 for the World: Secretary     \n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n"
     ]
    }
   ],
   "source": [
    "# Perform a Zero Shot Classification on the minidataset\n",
    "\n",
    "prompt_zero_shot = \"Is the following socila media post either Deception or Truth? \\\"{}\\\"\"\n",
    "zeroshot_actual_label_list = []\n",
    "zeroshot_predicted_label_list = []\n",
    "\n",
    "# iterate through each row of the minidataset\n",
    "for i in range(0, len(mini_dataset)):\n",
    "    print('sample number :', i)\n",
    "    sample_post = mini_dataset.loc[i]\n",
    "    print('Sample Post: ',sample_post['post'])\n",
    "    prompt = prompt_zero_shot.format(sample_post['post'])\n",
    "    result = classify_text(prompt)\n",
    "    print(f\"Actual Label: {sample_post['label']}\")\n",
    "    print(f\"Predicted Label: {result}\")\n",
    "    zeroshot_actual_label_list.append(sample_post['label'])\n",
    "    zeroshot_predicted_label_list.append(result)\n",
    "\n",
    "    \n",
    "results = pd.DataFrame({'Actual': zeroshot_actual_label_list, 'Predicted': zeroshot_predicted_label_list})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_file = 'zeroshot_results.csv'\n",
    "results.to_csv(os.path.join(base_path,'result_zero_shot',output_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6aa281",
   "metadata": {},
   "source": [
    "### Evaluate Zero-Shot Classification Results on a Mini Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ff1dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-score: 0.75\n"
     ]
    }
   ],
   "source": [
    "results_from_file = pd.read_csv(os.path.join(base_path,'result_zero_shot',output_file))\n",
    "\n",
    "# Extract the actual and predicted labels from the DataFrame\n",
    "actual_labels_from_file = results_from_file['Actual'].tolist()\n",
    "predicted_labels_from_file = results_from_file['Predicted'].tolist()\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(actual_labels_from_file, predicted_labels_from_file)\n",
    "precision = precision_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "recall = recall_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "f1 = f1_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "\n",
    "overall_zeroshot_result =[]\n",
    "overall_zeroshot_result.append(round(accuracy, 2))\n",
    "overall_zeroshot_result.append(round(precision, 2))\n",
    "overall_zeroshot_result.append(round(recall, 2))\n",
    "overall_zeroshot_result.append(round(f1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881d6f1",
   "metadata": {},
   "source": [
    "## Sample Selection for One-shot and Few-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a74e78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_samples(num_samples):\n",
    "    # Assign the class values\n",
    "    deceptive_class = 'Deception'\n",
    "    truthful_class = 'Truth'\n",
    "\n",
    "    # Separate the data into two classes based on label values\n",
    "    deceptive_data = mini_dataset[mini_dataset['label'] == deceptive_class]\n",
    "    truthful_data = mini_dataset[mini_dataset['label'] == truthful_class]\n",
    "\n",
    "    # Randomly select \"num_samples\" samples from each class\n",
    "    deceptive_sample = deceptive_data.sample(n=num_samples)\n",
    "    truthful_sample = truthful_data.sample(n=num_samples)\n",
    "    \n",
    "    # Concatenate deceptive and thruthful samples in one DataFrame\n",
    "    oneshot_samples = pd.concat([deceptive_sample, truthful_sample])\n",
    "\n",
    "    # Remove the selected samples from the original DataFrame\n",
    "    remaining_deceptive_data = deceptive_data.drop(deceptive_sample.index)\n",
    "    remaining_truthful_data = truthful_data.drop(truthful_sample.index)\n",
    "\n",
    "    # Combine the remaining samples\n",
    "    remaining_data = pd.concat([remaining_deceptive_data, remaining_truthful_data])\n",
    "\n",
    "    # Reset the index of the remaining data\n",
    "    remaining_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return oneshot_samples, remaining_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2036f59",
   "metadata": {},
   "source": [
    "## One-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd2e508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def oneshot_classify_text(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Label the text as 'Deception' or 'Truth'\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=200,\n",
    "        temperature=0.5,\n",
    "        stop=[':']\n",
    "    )\n",
    "    prediction = completion.choices[0].message['content'].strip()\n",
    "    label = prediction.split()[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3325e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_shot_learning():\n",
    "    # Initialize empty lists to store actual and predicted labels\n",
    "    actual_label_list = []\n",
    "    predicted_label_list = []\n",
    "    \n",
    "    # obtain one randomly sample from each class and store in selected_sample \n",
    "    # the remaining samples stored in remaining_samples_dataset\n",
    "    selected_sample, remaining_samples_dataset = select_samples(1)\n",
    "    \n",
    "    #seperate the samples based on their label\n",
    "    deceptive_class_sample = selected_sample[selected_sample['label'] == 'Deception']\n",
    "    truth_class_sample = selected_sample[selected_sample['label'] == 'Truth']\n",
    "    \n",
    "    deceptive_oneshot = deceptive_class_sample['post']\n",
    "    truth_oneshot = truth_class_sample['post']\n",
    "    \n",
    "    prompt_one_shot = (\n",
    "    f\"Below are two social media posts, either Deception or Truth\\n\"\n",
    "    f\"Deception: {deceptive_oneshot}\\n\"\n",
    "    f\"Truth: {truth_oneshot}\\n\"\n",
    "    )\n",
    "    print(prompt_one_shot)\n",
    "\n",
    "    for i in range(0, len(remaining_samples_dataset)):\n",
    "        print('sample number :', i)\n",
    "        sample_post = remaining_samples_dataset.loc[i]\n",
    "        print('Sample Post: ',sample_post['post'])\n",
    "\n",
    "        prompt = prompt_one_shot.format(sample_post['post'])\n",
    "        result = oneshot_classify_text(prompt)\n",
    "        print(f\"Actual Label: {sample_post['label']}\")\n",
    "        print(f\"Predicted Label: {result}\")\n",
    "        actual_label_list.append(sample_post['label'])\n",
    "        predicted_label_list.append(result)\n",
    "    \n",
    "    return actual_label_list, predicted_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a987e536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Shot Interation : 0\n",
      "Below are two social media posts, either Deception or Truth\n",
      "Deception: 0    There is a Nipah Virus outbreak in India amids...\n",
      "Name: post, dtype: object\n",
      "Truth: 9    : India's  Cases per Million population is amo...\n",
      "Name: post, dtype: object\n",
      "\n",
      "sample number : 0\n",
      "Sample Post:  \"Poll Finds 38% of Americans Say They Will Not Drink Corona Beer Because of Virus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 1\n",
      "Sample Post:  When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 2\n",
      "Sample Post:  The Gates Foundation \"has the patent for this coronavirus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 3\n",
      "Sample Post:  Tell me what Madeleine Albrights position was on the War on Iraq. I wouldnt be surprised if she supported it.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 4\n",
      "Sample Post:  (John) Kasich was the architect who balanced the budget, cut spending, created a surplus, igniting record job creation.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 5\n",
      "Sample Post:  As a result of Roe vs. Wade, Americas maternal mortality rate dropped dramatically.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 6\n",
      "Sample Post:   is when everyone has the opportunity to be as healthy as possible. Learn about the role of culture in your efforts to stop :  \n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 7\n",
      "Sample Post:  Energy nominee Steven Chu has called coal \"his worst nightmare.\"\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "One-Shot Interation : 1\n",
      "Below are two social media posts, either Deception or Truth\n",
      "Deception: 1    \"Poll Finds 38% of Americans Say They Will Not...\n",
      "Name: post, dtype: object\n",
      "Truth: 8    Energy nominee Steven Chu has called coal \"his...\n",
      "Name: post, dtype: object\n",
      "\n",
      "sample number : 0\n",
      "Sample Post:  There is a Nipah Virus outbreak in India amidst coronavirus pandemic, according to a warning form the WHO.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 1\n",
      "Sample Post:  When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 2\n",
      "Sample Post:  The Gates Foundation \"has the patent for this coronavirus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 3\n",
      "Sample Post:  Tell me what Madeleine Albrights position was on the War on Iraq. I wouldnt be surprised if she supported it.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 4\n",
      "Sample Post:  (John) Kasich was the architect who balanced the budget, cut spending, created a surplus, igniting record job creation.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 5\n",
      "Sample Post:  As a result of Roe vs. Wade, Americas maternal mortality rate dropped dramatically.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 6\n",
      "Sample Post:   is when everyone has the opportunity to be as healthy as possible. Learn about the role of culture in your efforts to stop :  \n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 7\n",
      "Sample Post:  : India's  Cases per Million population is amongst the lowest in the world; which stands at 3102 for India and 3527 for the World: Secretary     \n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "One-Shot Interation : 2\n",
      "Below are two social media posts, either Deception or Truth\n",
      "Deception: 4    Tell me what Madeleine Albrights position was ...\n",
      "Name: post, dtype: object\n",
      "Truth: 9    : India's  Cases per Million population is amo...\n",
      "Name: post, dtype: object\n",
      "\n",
      "sample number : 0\n",
      "Sample Post:  There is a Nipah Virus outbreak in India amidst coronavirus pandemic, according to a warning form the WHO.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 1\n",
      "Sample Post:  \"Poll Finds 38% of Americans Say They Will Not Drink Corona Beer Because of Virus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 2\n",
      "Sample Post:  When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 3\n",
      "Sample Post:  The Gates Foundation \"has the patent for this coronavirus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 4\n",
      "Sample Post:  (John) Kasich was the architect who balanced the budget, cut spending, created a surplus, igniting record job creation.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 5\n",
      "Sample Post:  As a result of Roe vs. Wade, Americas maternal mortality rate dropped dramatically.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 6\n",
      "Sample Post:   is when everyone has the opportunity to be as healthy as possible. Learn about the role of culture in your efforts to stop :  \n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 7\n",
      "Sample Post:  Energy nominee Steven Chu has called coal \"his worst nightmare.\"\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n"
     ]
    }
   ],
   "source": [
    "one_shot_iterations = 3\n",
    "for i in range(0, one_shot_iterations):\n",
    "    print('One-Shot Interation :',i)\n",
    "    act_label_list,  pre_label_list= one_shot_learning()\n",
    "    results = pd.DataFrame({'Actual': act_label_list, 'Predicted': pre_label_list})\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    output_file = str(i)+'_'+ 'oneshot_results.csv'\n",
    "    results.to_csv(os.path.join(base_path,'result_one_shot',output_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e9607",
   "metadata": {},
   "source": [
    "### Evaluate One-Shot Classification Results on a Mini Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "374fc091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n",
      "Precision: 0.50\n",
      "Recall: 1.00\n",
      "F1-score: 0.67\n"
     ]
    }
   ],
   "source": [
    "results_from_file = pd.read_csv(os.path.join(base_path,'result_one_shot','0_oneshot_results.csv'))\n",
    "\n",
    "# Extract the actual and predicted labels from the DataFrame\n",
    "actual_labels_from_file = results_from_file['Actual'].tolist()\n",
    "predicted_labels_from_file = results_from_file['Predicted'].tolist()\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(actual_labels_from_file, predicted_labels_from_file)\n",
    "precision = precision_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "recall = recall_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "f1 = f1_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc32efcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.50\n",
      "Average Precision: 0.50\n",
      "Average Recall: 1.00\n",
      "Average F1-score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to calculate averages\n",
    "total_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "num_files = 0\n",
    "\n",
    "base_path = \"\"  # Set the base path to your directory\n",
    "\n",
    "for filename in os.listdir(os.path.join(base_path, 'result_one_shot')):\n",
    "    if filename.endswith('_oneshot_results.csv'):\n",
    "        num_files += 1\n",
    "\n",
    "        results_from_file = pd.read_csv(os.path.join(base_path, 'result_one_shot', filename))\n",
    "\n",
    "        # Extract the actual and predicted labels from the DataFrame\n",
    "        actual_labels_from_file = results_from_file['Actual'].tolist()\n",
    "        predicted_labels_from_file = results_from_file['Predicted'].tolist()\n",
    "\n",
    "        # Calculate the accuracy, precision, recall, and F1-score\n",
    "        accuracy = accuracy_score(actual_labels_from_file, predicted_labels_from_file)\n",
    "        precision = precision_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "        recall = recall_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "        f1 = f1_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "\n",
    "        total_accuracy += accuracy\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "\n",
    "# Calculate the average accuracy, precision, recall, and F1-score\n",
    "avg_accuracy = total_accuracy / num_files\n",
    "avg_precision = total_precision / num_files\n",
    "avg_recall = total_recall / num_files\n",
    "avg_f1 = total_f1 / num_files\n",
    "\n",
    "# Print the average results\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")\n",
    "\n",
    "overall_oneshot_result =[]\n",
    "overall_oneshot_result.append(round(avg_accuracy, 2))\n",
    "overall_oneshot_result.append(round(avg_precision, 2))\n",
    "overall_oneshot_result.append(round(avg_recall, 2))\n",
    "overall_oneshot_result.append(round(avg_f1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a03ba9a",
   "metadata": {},
   "source": [
    "## Few-shot Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "118d2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fewshot_classify_text(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Label the text as 'Deception' or 'Truth'\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=200,\n",
    "        temperature=0.5,\n",
    "        stop=[':', \".\"]\n",
    "    )\n",
    "    prediction = completion.choices[0].message['content'].strip()\n",
    "    label = prediction.split()[0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c377bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def few_shot_learning(num_few):\n",
    "    # Initialize empty lists to store actual and predicted labels\n",
    "    actual_label_list = []\n",
    "    predicted_label_list = []\n",
    "    \n",
    "    # obtain \"num_few\" randomly samples from each class and store in selected_sample \n",
    "    # the remaining samples stored in remaining_samples_dataset\n",
    "    selected_samples, remaining_samples_dataset = select_samples(num_few)\n",
    "    \n",
    "    #seperate the samples based on their label\n",
    "    deceptive_class_sample = selected_samples[selected_samples['label'] == 'Deception']\n",
    "    truth_class_sample = selected_samples[selected_samples['label'] == 'Truth']\n",
    "    \n",
    "    deceptive_fewshot = deceptive_class_sample['post']\n",
    "    truth_fewshot = truth_class_sample['post']\n",
    "\n",
    "    # Few-shot learning\n",
    "    prompt_few_shot = \"Below are several social media posts, each labeled as either Deception or Truth:\\n\"\n",
    "\n",
    "    for i in range(num_few):\n",
    "        prompt_few_shot += f\"Deception: {deceptive_fewshot.iloc[i]}\\n\"\n",
    "        prompt_few_shot += f\"Truth: {truth_fewshot.iloc[i]}\\n\"\n",
    "\n",
    "    prompt_few_shot += \"Determine if the following post is either Deception or Truth: \\\"{}\\\"\"\n",
    "\n",
    "    for i in range(0, len(remaining_samples_dataset)):\n",
    "        print('sample number :', i)\n",
    "        sample_post = remaining_samples_dataset.loc[i]\n",
    "        print('Sample Post: ',sample_post['post'])\n",
    "\n",
    "        prompt = prompt_few_shot.format(sample_post['post'])\n",
    "        result = fewshot_classify_text(prompt)\n",
    "        print(f\"Actual Label: {sample_post['label']}\")\n",
    "        print(f\"Predicted Label: {result}\")\n",
    "        actual_label_list.append(sample_post['label'])\n",
    "        predicted_label_list.append(result)\n",
    "    results = pd.DataFrame({'Actual': actual_label_list, 'Predicted': predicted_label_list})\n",
    "    output_file = str(num_few)+'_fewshot_results.csv'\n",
    "    results.to_csv(os.path.join(base_path,'result_few_shot',output_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5e583ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number : 0\n",
      "Sample Post:  There is a Nipah Virus outbreak in India amidst coronavirus pandemic, according to a warning form the WHO.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Truth\n",
      "sample number : 1\n",
      "Sample Post:  When Obama was sworn into office, he DID NOT use the Holy Bible, but instead the Kuran (Their equivalency to our Bible, but very different beliefs).\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 2\n",
      "Sample Post:  The Gates Foundation \"has the patent for this coronavirus.\"\n",
      "Actual Label: Deception\n",
      "Predicted Label: Deception\n",
      "sample number : 3\n",
      "Sample Post:  (John) Kasich was the architect who balanced the budget, cut spending, created a surplus, igniting record job creation.\n",
      "Actual Label: Truth\n",
      "Predicted Label: Deception\n",
      "sample number : 4\n",
      "Sample Post:  Energy nominee Steven Chu has called coal \"his worst nightmare.\"\n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n",
      "sample number : 5\n",
      "Sample Post:  : India's  Cases per Million population is amongst the lowest in the world; which stands at 3102 for India and 3527 for the World: Secretary     \n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n"
     ]
    }
   ],
   "source": [
    "no_Fewshot_Reference = 2\n",
    "few_shot_learning(no_Fewshot_Reference)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e06683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67\n",
      "Precision: 0.67\n",
      "Recall: 0.67\n",
      "F1-score: 0.67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_from_file = pd.read_csv(os.path.join(base_path,'result_few_shot',str(no_Fewshot_Reference)+'_fewshot_results.csv'))\n",
    "\n",
    "# Extract the actual and predicted labels from the DataFrame\n",
    "actual_labels_from_file = results_from_file['Actual'].tolist()\n",
    "predicted_labels_from_file = results_from_file['Predicted'].tolist()\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(actual_labels_from_file, predicted_labels_from_file)\n",
    "precision = precision_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "recall = recall_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "f1 = f1_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "first_fewshot_result =[]\n",
    "first_fewshot_result.append(round(accuracy, 2))\n",
    "first_fewshot_result.append(round(precision, 2))\n",
    "first_fewshot_result.append(round(recall, 2))\n",
    "first_fewshot_result.append(round(f1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ebf64648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number : 0\n",
      "Sample Post:  There is a Nipah Virus outbreak in India amidst coronavirus pandemic, according to a warning form the WHO.\n",
      "Actual Label: Deception\n",
      "Predicted Label: Truth\n",
      "sample number : 1\n",
      "Sample Post:   is when everyone has the opportunity to be as healthy as possible. Learn about the role of culture in your efforts to stop :  \n",
      "Actual Label: Truth\n",
      "Predicted Label: Truth\n"
     ]
    }
   ],
   "source": [
    "no_Fewshot_Reference = 4\n",
    "few_shot_learning(no_Fewshot_Reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5870e8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.50\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_from_file = pd.read_csv(os.path.join(base_path,'result_few_shot',str(no_Fewshot_Reference)+'_fewshot_results.csv'))\n",
    "\n",
    "# Extract the actual and predicted labels from the DataFrame\n",
    "actual_labels_from_file = results_from_file['Actual'].tolist()\n",
    "predicted_labels_from_file = results_from_file['Predicted'].tolist()\n",
    "\n",
    "# Calculate the accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(actual_labels_from_file, predicted_labels_from_file)\n",
    "precision = precision_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "recall = recall_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "f1 = f1_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "second_fewshot_result =[]\n",
    "second_fewshot_result.append(round(accuracy, 2))\n",
    "second_fewshot_result.append(round(precision, 2))\n",
    "second_fewshot_result.append(round(recall, 2))\n",
    "second_fewshot_result.append(round(f1, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ffb1df",
   "metadata": {},
   "source": [
    "### Performance between different Fewshot values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3ce25b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# setting the bar width\n",
    "barWidth = 0.25\n",
    "\n",
    "# setting the positions of the bars on x-axis\n",
    "r1 = np.arange(len(first_fewshot_result))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "# plotting the bars\n",
    "bar1 = plt.bar(r1, first_fewshot_result, color='#7f6d5f', width=barWidth, edgecolor='grey', label='First_FewShot')\n",
    "bar2 = plt.bar(r2, second_fewshot_result, color='#557f2d', width=barWidth, edgecolor='grey', label='Second__FewShot')\n",
    "\n",
    "# Adding values inside the bars\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0, height / 2.0,\n",
    "                 '{0:.2f}'.format(height), ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "autolabel(bar1)\n",
    "autolabel(bar2)\n",
    "\n",
    "# adding the labels\n",
    "plt.xlabel('Metrics', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Values', fontweight='bold', fontsize=15)\n",
    "plt.xticks([r + barWidth for r in range(len(first_fewshot_result))], ['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# creating legend\n",
    "plt.legend()\n",
    "\n",
    "# showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ef82439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.76\n",
      "Average Precision: 0.67\n",
      "Average Recall: 0.60\n",
      "Average F1-score: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize variables to calculate averages\n",
    "total_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "num_files = 0\n",
    "\n",
    "base_path = \"\"  # Set the base path to your directory\n",
    "\n",
    "for filename in os.listdir(os.path.join(base_path, 'result_few_shot')):\n",
    "    if filename.endswith('_fewshot_results.csv'):\n",
    "        num_files += 1\n",
    "\n",
    "        results_from_file = pd.read_csv(os.path.join(base_path, 'result_few_shot', filename))\n",
    "\n",
    "        # Extract the actual and predicted labels from the DataFrame\n",
    "        actual_labels_from_file = results_from_file['Actual'].tolist()\n",
    "        predicted_labels_from_file = results_from_file['Predicted'].tolist()\n",
    "\n",
    "        # Calculate the accuracy, precision, recall, and F1-score\n",
    "        accuracy = accuracy_score(actual_labels_from_file, predicted_labels_from_file)\n",
    "        precision = precision_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "        recall = recall_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "        f1 = f1_score(actual_labels_from_file, predicted_labels_from_file, pos_label='Deception')\n",
    "\n",
    "        total_accuracy += accuracy\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "\n",
    "# Calculate the average accuracy, precision, recall, and F1-score\n",
    "avg_accuracy = total_accuracy / num_files\n",
    "avg_precision = total_precision / num_files\n",
    "avg_recall = total_recall / num_files\n",
    "avg_f1 = total_f1 / num_files\n",
    "\n",
    "# Print the average results\n",
    "print(f\"Average Accuracy: {avg_accuracy:.2f}\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")\n",
    "overall_fewshot_result =[]\n",
    "overall_fewshot_result.append(round(avg_accuracy, 2))\n",
    "overall_fewshot_result.append(round(avg_precision, 2))\n",
    "overall_fewshot_result.append(round(avg_recall, 2))\n",
    "overall_fewshot_result.append(round(avg_f1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c338604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d061ea31",
   "metadata": {},
   "source": [
    "### Overall Performance Graph average on each interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fd8ef11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# setting the bar width\n",
    "barWidth = 0.25\n",
    "\n",
    "# setting the positions of the bars on x-axis\n",
    "r1 = np.arange(len(overall_zeroshot_result))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "# plotting the bars\n",
    "bar1 = plt.bar(r1, overall_zeroshot_result, color='#7f6d5f', width=barWidth, edgecolor='grey', label='Zero Shot')\n",
    "bar2 = plt.bar(r2, overall_oneshot_result, color='#557f2d', width=barWidth, edgecolor='grey', label='One Shot')\n",
    "bar3 = plt.bar(r3, overall_fewshot_result, color='#2d7f5e', width=barWidth, edgecolor='grey', label='Few Shot')\n",
    "\n",
    "# Adding values inside the bars\n",
    "def autolabel(bars):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2.0, height / 2.0,\n",
    "                 '{0:.2f}'.format(height), ha='center', va='center', color='white', fontweight='bold')\n",
    "\n",
    "autolabel(bar1)\n",
    "autolabel(bar2)\n",
    "autolabel(bar3)\n",
    "\n",
    "# adding the labels\n",
    "plt.xlabel('Metrics', fontweight='bold', fontsize=15)\n",
    "plt.ylabel('Values', fontweight='bold', fontsize=15)\n",
    "plt.xticks([r + barWidth for r in range(len(overall_zeroshot_result))], ['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# creating legend\n",
    "plt.legend()\n",
    "\n",
    "# showing the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771a0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652126e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
